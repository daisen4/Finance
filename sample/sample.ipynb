{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.2020 - acc: 0.9401\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0798 - acc: 0.9759\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0514 - acc: 0.9836\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0274 - acc: 0.9912\n",
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06509487174618989, 0.9793]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3686 - acc: 0.9000\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1907 - acc: 0.9447\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1447 - acc: 0.9577\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1173 - acc: 0.9662\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0993 - acc: 0.9705\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0864 - acc: 0.9754\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0753 - acc: 0.9778\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0671 - acc: 0.9806\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0607 - acc: 0.9825\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0550 - acc: 0.9835\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0506 - acc: 0.9853\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0467 - acc: 0.9864\n",
      "10000/10000 [==============================] - 0s 24us/step\n",
      "0.0894979425090365\n",
      "0.9757\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像を1次元化\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# 画素を0~1の範囲に変換(正規化)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# 正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=784))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=100,\n",
    "            epochs=12,\n",
    "            verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2475 - acc: 0.9236 - val_loss: 0.1378 - val_acc: 0.9584\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1036 - acc: 0.9693 - val_loss: 0.0787 - val_acc: 0.9756\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0758 - acc: 0.9768 - val_loss: 0.0754 - val_acc: 0.9790\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0610 - acc: 0.9823 - val_loss: 0.0716 - val_acc: 0.9812\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0510 - acc: 0.9849 - val_loss: 0.0768 - val_acc: 0.9791\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0435 - acc: 0.9866 - val_loss: 0.0859 - val_acc: 0.9794\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0389 - acc: 0.9885 - val_loss: 0.0839 - val_acc: 0.9800\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0340 - acc: 0.9898 - val_loss: 0.0870 - val_acc: 0.9804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0302 - acc: 0.9911 - val_loss: 0.0787 - val_acc: 0.9813\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0287 - acc: 0.9918 - val_loss: 0.0983 - val_acc: 0.9802\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0281 - acc: 0.9920 - val_loss: 0.0921 - val_acc: 0.9819\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0257 - acc: 0.9929 - val_loss: 0.0981 - val_acc: 0.9810\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0239 - acc: 0.9938 - val_loss: 0.1150 - val_acc: 0.9806\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0255 - acc: 0.9932 - val_loss: 0.0993 - val_acc: 0.9823\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0224 - acc: 0.9938 - val_loss: 0.1060 - val_acc: 0.9827\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0204 - acc: 0.9946 - val_loss: 0.1050 - val_acc: 0.9841\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0206 - acc: 0.9948 - val_loss: 0.1137 - val_acc: 0.9828\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.1065 - val_acc: 0.9824\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0186 - acc: 0.9951 - val_loss: 0.1225 - val_acc: 0.9825\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0182 - acc: 0.9959 - val_loss: 0.1219 - val_acc: 0.9816\n",
      "Test loss: 0.12194352315971636\n",
      "Test accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像を1次元化\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# 画素を0~1の範囲に変換(正規化)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# 正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.2660 - acc: 0.9184 - val_loss: 0.0684 - val_acc: 0.9783\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0885 - acc: 0.9736 - val_loss: 0.0416 - val_acc: 0.9865\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0646 - acc: 0.9809 - val_loss: 0.0333 - val_acc: 0.9875\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0546 - acc: 0.9840 - val_loss: 0.0325 - val_acc: 0.9885\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0460 - acc: 0.9864 - val_loss: 0.0302 - val_acc: 0.9893\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.0260 - val_acc: 0.9908\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0373 - acc: 0.9884 - val_loss: 0.0313 - val_acc: 0.9892\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0346 - acc: 0.9895 - val_loss: 0.0268 - val_acc: 0.9912\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0329 - acc: 0.9900 - val_loss: 0.0295 - val_acc: 0.9899\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0299 - acc: 0.9909 - val_loss: 0.0264 - val_acc: 0.9922\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0264 - acc: 0.9918 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0254 - acc: 0.9920 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "Test loss: 0.027873626192573376\n",
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# 画像を1次元化\n",
    "#x_train = x_train.reshape(60000, 784)\n",
    "#x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# 画素を0~1の範囲に変換(正規化)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# 正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "#                 input_shape=x_train.shape[1:]))\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.2595 - acc: 0.9202 - val_loss: 0.0576 - val_acc: 0.9817\n",
      "Test loss: 0.05757859550863505\n",
      "save the architecture of a model\n",
      "save weights\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "Copied from\n",
    "https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os.path\n",
    "from keras.utils import plot_model\n",
    "#from keras.utils.visualize_util import plot\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1#12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "print('save the architecture of a model')\n",
    "json_string = model.to_json()\n",
    "open('./model/cnn_model.json', 'w').write(json_string)\n",
    "yaml_string = model.to_yaml()\n",
    "open('./model/cnn_model.yaml', 'w').write(yaml_string)\n",
    "print('save weights')\n",
    "model.save_weights(os.path.join('./model/cnn_model_weights.hdf5'))\n",
    "#plot(model, to_file='./model/model.png')\n",
    "plot_model(model, to_file='./model/model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate IRNN...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer simple_rnn_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d1f887c5d7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mrecurrent_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     input_shape=x_train.shape[1:]))\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer simple_rnn_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像を1次元化\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# 画素を0~1の範囲に変換(正規化)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# 正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "hidden_units = 100\n",
    "\n",
    "learning_rate = 1e-6\n",
    "clip_norm = 1.0\n",
    "\n",
    "print('Evaluate IRNN...')\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_units,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
    "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
    "                    activation='relu',\n",
    "                    input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "rmsprop = RMSprop(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('IRNN test score:', scores[0])\n",
    "print('IRNN test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
